# =============================================================================
# RAGScore Configuration
# =============================================================================
# RAGScore auto-detects which provider to use based on available API keys.
# Set ONE of the following API keys to get started.

# =============================================================================
# LLM Provider API Keys (choose one or more)
# =============================================================================

# --- Popular Cloud Providers ---

# OpenAI (GPT-4, GPT-4o, GPT-3.5)
# Get key: https://platform.openai.com/api-keys
# OPENAI_API_KEY="sk-..."

# Anthropic (Claude 3 Opus, Sonnet, Haiku)
# Get key: https://console.anthropic.com/
# ANTHROPIC_API_KEY="sk-ant-..."

# DashScope / Qwen (Alibaba Cloud) - Great for Chinese content
# Get key: https://dashscope.console.aliyun.com/
# DASHSCOPE_API_KEY="sk-..."

# --- Fast Inference Providers ---

# Groq (Llama, Mixtral - extremely fast)
# Get key: https://console.groq.com/
# GROQ_API_KEY="gsk_..."

# Together AI (Llama, Mistral, many open models)
# Get key: https://api.together.xyz/
# TOGETHER_API_KEY="..."

# Fireworks AI
# Get key: https://fireworks.ai/
# FIREWORKS_API_KEY="..."

# --- Other Providers ---

# Grok (xAI)
# Get key: https://console.x.ai/
# XAI_API_KEY="xai-..."

# Mistral AI
# Get key: https://console.mistral.ai/
# MISTRAL_API_KEY="..."

# DeepSeek
# Get key: https://platform.deepseek.com/
# DEEPSEEK_API_KEY="..."

# Perplexity
# Get key: https://www.perplexity.ai/settings/api
# PERPLEXITY_API_KEY="pplx-..."

# OpenRouter (access to many models via one API)
# Get key: https://openrouter.ai/keys
# OPENROUTER_API_KEY="..."

# Azure OpenAI
# AZURE_OPENAI_API_KEY="..."
# AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"

# =============================================================================
# Local LLM (Ollama) - No API key needed!
# =============================================================================
# Install Ollama: https://ollama.ai/
# Run: ollama serve
# Pull a model: ollama pull llama2
#
# OLLAMA_BASE_URL="http://localhost:11434"
# OLLAMA_MODEL="llama2"

# =============================================================================
# Custom OpenAI-Compatible Endpoint
# =============================================================================
# Use any OpenAI-compatible API (vLLM, LocalAI, text-generation-webui, etc.)
#
# LLM_BASE_URL="http://localhost:8000/v1"
# LLM_API_KEY="not-needed"
# LLM_MODEL="my-model"

# =============================================================================
# RAGScore Configuration Options
# =============================================================================
# Optional: Customize RAGScore behavior
#
# RAGSCORE_CHUNK_SIZE=512
# RAGSCORE_QUESTIONS_PER_CHUNK=5
# RAGSCORE_WORK_DIR=/path/to/workspace
