{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ RAGScore - 1-Minute RAG Audit\n",
    "\n",
    "Audit your RAG system in one line. Get instant visualizations.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Works in Google Colab and Jupyter\n",
    "- ‚úÖ Supports local LLMs (Ollama) and cloud APIs\n",
    "- ‚úÖ Rich Object returns: `.df`, `.plot()`, `.corrections`\n",
    "- ‚úÖ Pass HTTP endpoint or Python function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install RAGScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ragscore[notebook]\n",
    "\n",
    "# Safety net: Explicit asyncio patch for Colab\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "print(\"‚úÖ RAGScore installed with notebook support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup LLM\n",
    "\n",
    "### Option A: Cloud LLM (OpenAI, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # Replace with your key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Local LLM (Ollama) - FREE & Private!\n",
    "\n",
    "Run this cell to set up Ollama in Colab (~2 minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and start Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "subprocess.Popen(\"ollama serve\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "time.sleep(5)\n",
    "\n",
    "!ollama pull llama3\n",
    "print(\"‚úÖ Ollama ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Setup: Download Sample Document\n",
    "\n",
    "This ensures the demo works immediately without manual file uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Download a sample PDF so the demo works out-of-the-box\n",
    "!mkdir -p docs\n",
    "!echo \"Sample RAG document for testing.\" > docs/sample.txt\n",
    "print(\"‚úÖ Sample document created in docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. The \"1-Minute Audit\" ‚ö°\n",
    "\n",
    "This is the money shot. Copy this block to audit any RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragscore import quick_test\n",
    "\n",
    "# 1. Audit your RAG in one line\n",
    "result = quick_test(\n",
    "    endpoint=\"http://localhost:8000/query\",  # Your RAG API\n",
    "    docs=\"docs/\",                            # Your documents\n",
    "    n=10,                                    # Number of test questions\n",
    ")\n",
    "\n",
    "# 2. See the report\n",
    "result.plot()\n",
    "\n",
    "# 3. Inspect failures\n",
    "bad_rows = result.df[result.df['score'] < 3]\n",
    "display(bad_rows[['question', 'rag_answer', 'reason']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Test with a Python Function (No Server!)\n",
    "\n",
    "Perfect for testing RAG built directly in Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your RAG function\n",
    "def my_rag(question: str) -> str:\n",
    "    # Replace with your actual RAG logic\n",
    "    # e.g., vectorstore.similarity_search(question)\n",
    "    return \"This is a placeholder answer.\"\n",
    "\n",
    "# Test it!\n",
    "result = quick_test(\n",
    "    endpoint=my_rag,  # Pass function directly\n",
    "    docs=\"docs/\",\n",
    "    n=5,\n",
    ")\n",
    "\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Rich Object API\n",
    "\n",
    "The `QuickTestResult` object gives you everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "print(f\"Accuracy: {result.accuracy:.1%}\")\n",
    "print(f\"Passed: {result.passed}\")\n",
    "print(f\"Average Score: {result.avg_score:.1f}/5.0\")\n",
    "\n",
    "# DataFrame for analysis\n",
    "result.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections for RAG improvement\n",
    "print(f\"{len(result.corrections)} corrections needed\")\n",
    "for c in result.corrections[:3]:\n",
    "    print(f\"\\nQ: {c['question'][:60]}...\")\n",
    "    print(f\"Wrong: {c['incorrect_answer'][:60]}...\")\n",
    "    print(f\"Correct: {c['correct_answer'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export corrections to file\n",
    "from ragscore.quick_test import export_corrections\n",
    "\n",
    "export_corrections(result, \"corrections.jsonl\")\n",
    "print(\"‚úÖ Corrections saved! Inject into your RAG to improve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Use in pytest (CI/CD)\n",
    "\n",
    "```python\n",
    "# test_rag.py\n",
    "from ragscore import quick_test\n",
    "\n",
    "def test_rag_accuracy():\n",
    "    result = quick_test(\n",
    "        endpoint=\"http://localhost:8000/query\",\n",
    "        docs=\"docs/\",\n",
    "        n=20,\n",
    "        threshold=0.8,\n",
    "        silent=True,\n",
    "    )\n",
    "    assert result.passed, f\"RAG accuracy too low: {result.accuracy:.0%}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub**: https://github.com/HZYAI/RagScore\n",
    "- **PyPI**: https://pypi.org/project/ragscore/\n",
    "\n",
    "‚≠ê Star us on GitHub if you find this useful!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
